{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31260,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q docling chromadb langchain-text-splitters sentence-transformers torch accelerate","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport io\nimport time\nimport google.generativeai as genai\nfrom PIL import Image\nfrom docling.document_converter import DocumentConverter, PdfFormatOption\nfrom docling.datamodel.pipeline_options import PdfPipelineOptions, AcceleratorOptions\nfrom langchain_text_splitters import MarkdownHeaderTextSplitter\nfrom docling.datamodel.base_models import InputFormat\nfrom docling_core.types.doc import DocItemLabel\nfrom sentence_transformers import SentenceTransformer\nimport chromadb\nimport urllib.request\n\nGEMINI_API_KEY = \"AIzaSyDCA5qkmHinWpxJ_4TVzR1Y208PvHCAzZ4\" \ngenai.configure(api_key=GEMINI_API_KEY)\nvision_model = genai.GenerativeModel('gemini-2.5-flash-lite')\n\nos.makedirs(\"/kaggle/working/data\", exist_ok=True)\nos.makedirs(\"/kaggle/working/images\", exist_ok=True)\n\nprint(\"Setup Complete.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pdf_url = \"https://ir.tesla.com/_flysystem/s3/sec/000162828024002390/tsla-20231231-gen.pdf\"\npdf_path = \"/kaggle/working/data/tesla_2023_10k.pdf\"\nurllib.request.urlretrieve(pdf_url, pdf_path)\n\nprint(\"PDF Downloaded successfully!\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pipeline_options = PdfPipelineOptions()\npipeline_options.accelerator_options = AcceleratorOptions(num_threads=4, device=\"cuda\")\n\npipeline_options.images_scale = 2.0 \npipeline_options.generate_page_images = True \n\nconverter = DocumentConverter(\n    format_options={\n        InputFormat.PDF: PdfFormatOption(pipeline_options=pipeline_options)\n    }\n)\n\nstart = time.time()\nresult = converter.convert(pdf_path)\nend = time.time()\nprint(f\"Conversion Done in {end - start:.2f} seconds!\")\n\nmarkdown_text = result.document.export_to_markdown()\n\nwith open(\"/kaggle/working/tesla.md\", \"w\") as f:\n    f.write(markdown_text)\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"visual_data = []\n\nprint(\"Extracting images and analyzing with Gemini...\")\noutput_dir = \"/kaggle/working/images\"\n\nfor element, level in result.document.iterate_items():\n    if element.label == DocItemLabel.PICTURE:\n        page_no = element.prov[0].page_no if element.prov else \"unknown\"\n        \n        img = None\n        if hasattr(element, 'image') and element.image is not None:\n            img = element.image.pil_image\n        else:\n            try:\n                img = element.get_image(result.document)\n            except:\n                continue\n\n        if img:\n            img_filename = f\"tesla_p{page_no}_{id(element)}.png\"\n            img_path = os.path.join(output_dir, img_filename)\n            img.save(img_path)\n            \n            prompt = f\"\"\"Analyze this image from Tesla's 10-K report (Page {page_no}). \n            Provide a structured summary:\n            1. What is this chart/image showing?\n            2. Exact numbers or data points visible.\n            3. The key trend or takeaway.\n            Format output clearly.\"\"\"\n            \n            try:\n                response = vision_model.generate_content([prompt, img])\n                \n                visual_data.append({\n                    \"text\": f\"[IMAGE SUMMARY]: {response.text}\", \n                    \"metadata\": {\n                        \"page_number\": page_no,\n                        \"content_type\": \"visual\",\n                        \"file_name\": img_filename,\n                        \"display_mode\": \"image_only\" \n                    }\n                })\n            \n                print(f\" Analyzed image on page {page_no}\")\n            except Exception as e:\n                print(f\" Gemini failed on page {page_no}: {e}\")\n\n\nprint(f\"Successfully processed {len(visual_data)} images.\")\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from docling_core.types.doc import PictureItem, TableItem, SectionHeaderItem\nfrom langchain_text_splitters import RecursiveCharacterTextSplitter\n\ntext_splitter = RecursiveCharacterTextSplitter(\n    chunk_size=1000,\n    chunk_overlap=100,\n    add_start_index=True\n)\n\ntext_data = []\nlast_text_context = \"\" \ncurrent_section = \"General\" \n\nfor element, level in result.document.iterate_items():\n    if isinstance(element, PictureItem):\n        continue\n    \n    page_no = int(element.prov[0].page_no) if element.prov else 0\n    \n    if isinstance(element, TableItem):\n        table_markdown = element.export_to_markdown(result.document)\n        \n\n        bridge_prompt = f\"\"\"\n            Act as a professional Financial Data Indexer. Your goal is to write a high-density keyword summary for a retrieval system (RAG) to index this specific table.\n            \n            CONTEXT OF THE DOCUMENT:\n            \"{last_text_context}\"\n            \n            TABLE DATA (MARKDOWN):\n            {table_markdown}\n            \n            TASK:\n            Generate a dense, 6-to-7 sentence summary that makes this table highly searchable. \n            Do NOT use generic phrases like \"This table shows.\"\n            \n            REQUIRED ELEMENTS TO INCLUDE:\n            1. THE CORE TOPIC: What specific financial or operational data is being measured?\n            2. COLUMN HEADERS: Explicitly list every column header.\n            3. ROW ENTITIES: Explicitly list the primary entities or categories in the rows (e.g., specific products, subsidiaries, or dates).\n            4. TERMS & STATUSES: Include any specific keywords, metrics, or status labels found in the cells (e.g., \"Pilot production\", \"Adjusted EBITDA\", \"Restricted\").\n            5. SYMBOL CLARIFICATION: If the preceding context explains what symbols like dashes (â€”) or asterisks (*) mean in this table, state that meaning (e.g., \"Dashes indicate milestones not yet achieved\").\n            \n            OUTPUT FORMAT:\n            \"Topic: [Topic]. Headers: [Headers]. Entities/Rows: [Rows]. Key Metrics/Statuses: [Keywords].\"\n        \"\"\"\n        try:\n            table_enrichment = vision_model.generate_content(bridge_prompt).text\n            time.sleep(7) \n        except:\n            print(f\" Gemini failed on page {page_no}: {e}\")\n            table_enrichment = \"Tesla Financial Data Table.\"\n\n        content = f\"{table_enrichment} \\n---UI_SEPARATOR---\\n {table_markdown}\"\n        c_type = \"table\"\n        \n    elif isinstance(element, SectionHeaderItem):\n        content = f\"{'#' * element.level} {element.text}\"\n        current_section = element.text \n        last_text_context = content\n        c_type = \"text\"\n    else:\n        content = element.text\n        if len(content) > 100:\n            last_text_context = content\n        c_type = \"text\"\n    \n    if not content or len(content.strip()) < 40:\n        continue\n\n    if len(content) > 1000 and not isinstance(element, TableItem):\n        sub_chunks = text_splitter.split_text(content)\n        for sub in sub_chunks:\n            text_data.append({\n                \"text\": sub,\n                \"metadata\": {\n                    \"page_number\": page_no,\n                    \"content_type\": c_type,\n                    \"section\": current_section,\n                    \"file_name\": \"tesla_2023_10k.pdf\",\n                    \"is_sub_chunk\": True\n                }\n            })\n    else:\n        text_data.append({\n            \"text\": content,\n            \"metadata\": {\n                \"page_number\": page_no,\n                \"content_type\": c_type,\n                \"section\": current_section,\n                \"file_name\": \"tesla_2023_10k.pdf\",\n                \"is_sub_chunk\": False \n            }\n        })\n\nprint(f\"Total chunks created: {len(text_data)}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"client = chromadb.PersistentClient(path=\"/kaggle/working/chroma_db\")\ncollection = client.get_or_create_collection(name=\"tesla_reports\")\n\nembed_model = SentenceTransformer('all-MiniLM-L6-v2')\n\nall_entries = text_data + visual_data\n\ndocs = [item[\"text\"] for item in all_entries]\nmetas = [item[\"metadata\"] for item in all_entries]\nids = [f\"id_{i}\" for i in range(len(all_entries))]\n\nprint(\"Generating embeddings and saving to ChromaDB...\")\nembeddings = embed_model.encode(docs, show_progress_bar=True).tolist()\n\ncollection.add(\n    documents=docs,\n    embeddings=embeddings,\n    metadatas=metas,\n    ids=ids\n)\n\nprint(\"Database built successfully!\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import shutil\n\nshutil.make_archive(\"/kaggle/working/financial_rag_data\", 'zip', \"/kaggle/working/\", \"chroma_db\")\n!zip -ur /kaggle/working/financial_rag_data.zip /kaggle/working/images /kaggle/working/data/tesla_2023_10k.pdf\n\nfrom IPython.display import FileLink\nFileLink(r'financial_rag_data.zip')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}